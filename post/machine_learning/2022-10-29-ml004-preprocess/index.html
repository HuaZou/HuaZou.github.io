<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: January 17, 2024 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.e5d7adca760216d3b7e28ea434e81f6f.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><script async src="https://www.googletagmanager.com/gtag/js?id=UA-162525500-1"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(e,t){gtag("event","click",{event_category:"outbound",event_label:e,transport_type:"beacon",event_callback:function(){t!=="_blank"&&(document.location=e)}}),console.debug("Outbound link clicked: "+e)}function onClickCallback(e){if(e.target.tagName!=="A"||e.target.host===window.location.host)return;trackOutboundLink(e.target,e.target.getAttribute("target"))}gtag("js",new Date),gtag("config","UA-162525500-1",{}),gtag("set",{cookie_flags:"SameSite=None;Secure"}),document.addEventListener("click",onClickCallback,!1)</script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?67583aee7371a754cff04fa0a471bca3",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><meta name=author content="Hua Zou"><meta name=description content="Data PreProcessing before building machine learning model."><link rel=alternate hreflang=en-us href=https://zouhua.top/post/machine_learning/2022-10-29-ml004-preprocess/><link rel=canonical href=https://zouhua.top/post/machine_learning/2022-10-29-ml004-preprocess/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hub9a637e5d84e6d4c134f91fa57903eec_55838_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hub9a637e5d84e6d4c134f91fa57903eec_55838_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@Hua Zou"><meta property="twitter:creator" content="@Hua Zou"><meta property="twitter:image" content="https://zouhua.top/media/icon_hub9a637e5d84e6d4c134f91fa57903eec_55838_512x512_fill_lanczos_center_3.png"><meta property="og:site_name" content="Hua's Cabin"><meta property="og:url" content="https://zouhua.top/post/machine_learning/2022-10-29-ml004-preprocess/"><meta property="og:title" content="Machine Learning on gut microbiota of patients with Colorectal cancer (4) | Hua's Cabin"><meta property="og:description" content="Data PreProcessing before building machine learning model."><meta property="og:image" content="https://zouhua.top/media/icon_hub9a637e5d84e6d4c134f91fa57903eec_55838_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2022-10-29T20:13:14+00:00"><meta property="article:modified_time" content="2022-10-29T22:13:14+00:00"><title>Machine Learning on gut microbiota of patients with Colorectal cancer (4) | Hua's Cabin</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=8ce44869d16e09d570d820f26382542d><script src=/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js></script><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Hua's Cabin</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Hua's Cabin</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#posts><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li><li class=nav-item><a class=nav-link href=/#bookdown><span>Bookdown</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class="container-fluid docs"><div class="row flex-xl-nowrap"><div class="col-12 col-md-3 col-xl-2 docs-sidebar"><form class="docs-search d-flex align-items-center"><button class="btn docs-toggle d-md-none p-0 mr-md-3 w-100" type=button data-toggle=collapse data-target=#docs-nav aria-controls=docs-nav aria-expanded=false aria-label="Toggle section navigation"><div class=d-flex><span class="d-md-none pl-1 flex-grow-1 text-left overflow-hidden">Posts</span>
<span><i class="fas fa-chevron-down"></i></span></div></button></form><nav class="collapse docs-links" id=docs-nav><ul class="nav docs-sidenav"><li><a href=/post/><i class="fas fa-arrow-left pr-1"></i>Posts</a></li></ul><li class=active><a href=/post/machine_learning/2022-10-29-ml004-preprocess/>Machine Learning on gut microbiota of patients with Colorectal cancer (4)</a></li></nav></div><div class="d-none d-xl-block col-xl-2 docs-toc"><ul class="nav toc-top"><li><a href=# id=back_to_top class=docs-toc-title>Contents</a></li></ul><nav id=TableOfContents><ul><li><a href=#goal>Goal</a></li><li><a href=#loading-data-and-essential-libraries>Loading data and essential libraries</a></li><li><a href=#importing-data>Importing data</a></li><li><a href=#label-encoding>Label encoding</a></li><li><a href=#centered-log-ratio-clr-transformation>centered log-ratio (clr) transformation</a></li><li><a href=#assesing-model-accuracy-split-data-into-training-and-test-sets>Assesing Model Accuracy: Split data into training and test sets</a></li><li><a href=#feature-standardization>Feature Standardization</a></li><li><a href=#feature-decomposition-using-principal-component-analysis-pca>Feature decomposition using Principal Component Analysis (PCA)</a></li><li><a href=#deciding-how-many-principal-components-to-retain>Deciding How Many Principal Components to Retain</a></li><li><a href=#static3dplot>Static3Dplot</a></li><li><a href=#compositional-biplot>Compositional biplot</a><ul><li><a href=#observation>Observation</a></li></ul></li><li><a href=#output>Output</a></li><li><a href=#a-summary-of-the-data-preprocing-approach-used-here>A Summary of the Data Preprocing Approach used here:</a></li><li><a href=#reference>Reference</a></li></ul></nav></div><main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role=main><div class=docs-article-container></div><div class=docs-article-container><h1>Machine Learning on gut microbiota of patients with Colorectal cancer (4)</h1><article class=article-style><h1 id=data-preprocessing>Data PreProcessing</h1><p><a href=https://github.com/HuaZou/Machine-Learning-on-gut-microbiota-of-patients-with-Colorectal-cancer/blob/main/03.DataPreprocesing.ipynb target=_blank rel=noopener>Notebook 4</a> Pre-Processing the data.</p><p><a href=http://www.cs.ccsu.edu/~markov/ccsu_courses/datamining-3.html target=_blank rel=noopener>Data preprocessing</a> is a crucial step for any data analysis problem. It is often a very good idea to prepare your data in such way to best expose the structure of the problem to the machine learning algorithms that you intend to use. This involves a number of activities such as:</p><ul><li>Assigning numerical values to categorical data;</li><li>Handling missing values;</li><li>Normalizing the features (so that features on small scales do not dominate when fitting a model to the data).</li></ul><p>In <strong>Exploratory Data Analysis</strong>, I explored the data, to help gain insight on the distribution of the data as well as how the attributes correlate to each other. I identified some features of interest. In this notebook I use feature selection to reduce high-dimension data, feature extraction and transformation for dimensional reduction.</p><h2 id=goal>Goal</h2><p>Find the most predictive features of the data and filter it so it will enhance the predictive power of the analytics model.</p><h2 id=loading-data-and-essential-libraries>Loading data and essential libraries</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>%</span><span class=n>matplotlib</span> <span class=n>inline</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span> 
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy.stats</span> <span class=kn>import</span> <span class=n>norm</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># visualization</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>seaborn</span> <span class=k>as</span> <span class=nn>sns</span> 
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>style</span><span class=o>.</span><span class=n>use</span><span class=p>(</span><span class=s1>&#39;fivethirtyeight&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>sns</span><span class=o>.</span><span class=n>set_style</span><span class=p>(</span><span class=s2>&#34;white&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>rcParams</span><span class=p>[</span><span class=s1>&#39;figure.figsize&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=mi>8</span><span class=p>,</span><span class=mi>4</span><span class=p>)</span> 
</span></span><span class=line><span class=cl><span class=c1>#plt.rcParams[&#39;axes.titlesize&#39;] = &#39;large&#39;</span>
</span></span></code></pre></div><h2 id=importing-data>Importing data</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>data_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_table</span><span class=p>(</span><span class=s1>&#39;./dataset/MergeData.tsv&#39;</span><span class=p>,</span> <span class=n>sep</span><span class=o>=</span><span class=s2>&#34;</span><span class=se>\t</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>index_col</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=o>=</span> <span class=n>data_df</span><span class=o>.</span><span class=n>reset_index</span><span class=p>(</span><span class=n>drop</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>data</span><span class=o>.</span><span class=n>head</span><span class=p>()</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=https://raw.githubusercontent.com/HuaZou/Image_Host/main/img/image-20221102102829091.png alt loading=lazy data-zoomable></div></div></figure></p><h2 id=label-encoding>Label encoding</h2><p>Here, I assign the features to a NumPy array X, and transform the class labels from their original string representation (CRC and healthy) into integers</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>array</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>values</span>
</span></span><span class=line><span class=cl><span class=n>X_temp</span> <span class=o>=</span> <span class=n>array</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>:</span><span class=n>data</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>=</span> <span class=n>array</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>array</span>
</span></span></code></pre></div><pre><code>array([['healthy', 46509517, 8249892, ..., 0, 0, 0],
       ['healthy', 5334509, 230275, ..., 0, 0, 0],
       ['healthy', 6868169, 4054008, ..., 0, 0, 0],
       ...,
       ['healthy', 0, 0, ..., 0, 0, 0],
       ['healthy', 2286204, 242316, ..., 630160, 653, 191409],
       ['healthy', 0, 0, ..., 0, 0, 0]], dtype=object)
</code></pre><h2 id=centered-log-ratio-clr-transformation>centered log-ratio (clr) transformation</h2><p>Transforms compositions from Aitchison geometry to the real space (<a href=http://scikit-bio.org/docs/0.4.2/generated/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr target=_blank rel=noopener>skbio.stats.composition.clr</a>).</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>skbio.stats.composition</span> <span class=kn>import</span> <span class=n>clr</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>pseude_value</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>amin</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>X_temp</span><span class=p>)[</span><span class=n>X_temp</span> <span class=o>!=</span> <span class=n>np</span><span class=o>.</span><span class=n>amin</span><span class=p>(</span><span class=n>X_temp</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>data_temp</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>:</span><span class=n>data</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]]</span><span class=o>.</span><span class=n>T</span>
</span></span><span class=line><span class=cl><span class=n>data_clr</span> <span class=o>=</span> <span class=n>data_temp</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>clr</span><span class=p>(</span><span class=n>x</span> <span class=o>+</span> <span class=n>pseude_value</span><span class=p>),</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>T</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>data_clr</span><span class=o>.</span><span class=n>values</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>:</span><span class=n>data_clr</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=n>X</span>
</span></span></code></pre></div><pre><code>array([[10.26214602,  8.53269436,  7.7298392 , ..., -3.44177889,
        -3.44177889, -3.44177889],
       [ 7.60933349,  4.46687166,  6.65482253, ..., -3.92913994,
        -3.92913994, -3.92913994],
       [ 8.41126745,  7.88408118,  7.66846676, ..., -3.37990451,
        -3.37990451, -3.37990451],
       ...,
       [-1.88844976, -1.88844976,  6.09721786, ..., -1.88844976,
        -1.88844976, -1.88844976],
       [ 7.74550107,  5.50128747,  7.86826035, ...,  6.45688651,
        -0.33872724,  5.26551437],
       [-1.22443516, -1.22443516, -1.22443516, ..., -1.22443516,
        -1.22443516, -1.22443516]])
</code></pre><ul><li>transform the class labels from their original string representation (CRC and healthy) into integers</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>LabelEncoder</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>le</span> <span class=o>=</span> <span class=n>LabelEncoder</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>=</span> <span class=n>le</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>#Call the transform method of LabelEncorder on two dummy variables</span>
</span></span><span class=line><span class=cl><span class=c1>#le.transform ([&#39;CRC&#39;, &#39;healthy&#39;])</span>
</span></span><span class=line><span class=cl><span class=n>y</span>
</span></span></code></pre></div><pre><code>array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,
       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,
       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,
       1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,
       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,
       0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,
       1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,
       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,
       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,
       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,
       0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,
       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,
       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,
       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,
       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,
       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,
       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,
       0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
</code></pre><blockquote><p><em>After encoding the class labels(disease) in an array y, the Responsed patients are now represented as class 1(i.e prescence of Response) and the Non-Responsed patients are represented as class 0 (i.e healthy), respectively</em>, illustrated by calling the transform method of LabelEncorder on two dummy variables.</p></blockquote><h2 id=assesing-model-accuracy-split-data-into-training-and-test-sets>Assesing Model Accuracy: Split data into training and test sets</h2><p>The simplest method to evaluate the performance of a machine learning algorithm is to use different training and testing datasets. Here I will</p><ul><li>Split the available data into a training set and a testing set. (70% training, 30% test)</li><li>Train the algorithm on the first part,</li><li>make predictions on the second part and</li><li>evaluate the predictions against the expected results.</li></ul><p>The size of the split can depend on the size and specifics of your dataset, although it is common to use 67% of the data for training and the remaining 33% for testing.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.model_selection</span> <span class=kn>import</span> <span class=n>train_test_split</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>##Split data set in train 70% and test 30%</span>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>7</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>y_train</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>X_test</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>y_test</span><span class=o>.</span><span class=n>shape</span>
</span></span></code></pre></div><pre><code>((352, 151), (352,), (152, 151), (152,))
</code></pre><h2 id=feature-standardization>Feature Standardization</h2><ul><li><p>Standardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1.</p></li><li><p>As seen in <strong>Exploratory Data Analysis</strong> the raw data has differing distributions (left skew distributions) which may have an impact on the most ML algorithms. Most machine learning and optimization algorithms behave much better if features are on the same scale.</p></li></ul><p>Let’s evaluate the same algorithms with a standardized copy of the dataset. Here, I use sklearn to scale and transform the data such that each attribute has a mean value of zero and a standard deviation of one.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>StandardScaler</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Normalize the  data (center around 0 and scale to remove the variance).</span>
</span></span><span class=line><span class=cl><span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>Xs</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=feature-decomposition-using-principal-component-analysis-pca>Feature decomposition using Principal Component Analysis (PCA)</h2><p>From the pair plot in <strong>Exploratory Data Analysis</strong>, lots of feature pairs divide nicely the data to a similar extent, therefore, it makes sense to use one of the dimensional reduction methods to try to use as many features as possible and maintain as much information as possible when working with only 2 dimensions.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.decomposition</span> <span class=kn>import</span> <span class=n>PCA</span>
</span></span><span class=line><span class=cl><span class=c1># feature extraction</span>
</span></span><span class=line><span class=cl><span class=n>pca</span> <span class=o>=</span> <span class=n>PCA</span><span class=p>(</span><span class=n>n_components</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>fit</span> <span class=o>=</span> <span class=n>pca</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>Xs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># summarize components</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Explained Variance: </span><span class=si>%s</span><span class=s2>&#34;</span> <span class=o>%</span> <span class=n>fit</span><span class=o>.</span><span class=n>explained_variance_ratio_</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>Explained Variance: [0.12475653 0.07725227 0.0362945  0.03049992 0.02403753 0.01906391
 0.01846672 0.01726657 0.01640619 0.01474633]
</code></pre><ul><li>PCA plot</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>X_pca</span> <span class=o>=</span> <span class=n>pca</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>Xs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>PCA_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>PCA_df</span><span class=p>[</span><span class=s1>&#39;PCA_1&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>X_pca</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>PCA_df</span><span class=p>[</span><span class=s1>&#39;PCA_2&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>X_pca</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>6</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>PCA_df</span><span class=p>[</span><span class=s1>&#39;PCA_1&#39;</span><span class=p>][</span><span class=n>data</span><span class=o>.</span><span class=n>disease</span> <span class=o>==</span> <span class=s1>&#39;CRC&#39;</span><span class=p>],</span> <span class=n>PCA_df</span><span class=p>[</span><span class=s1>&#39;PCA_2&#39;</span><span class=p>][</span><span class=n>data</span><span class=o>.</span><span class=n>disease</span> <span class=o>==</span> <span class=s1>&#39;CRC&#39;</span><span class=p>],</span> <span class=s1>&#39;o&#39;</span><span class=p>,</span> <span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.7</span><span class=p>,</span> <span class=n>color</span> <span class=o>=</span> <span class=s1>&#39;r&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>PCA_df</span><span class=p>[</span><span class=s1>&#39;PCA_1&#39;</span><span class=p>][</span><span class=n>data</span><span class=o>.</span><span class=n>disease</span> <span class=o>==</span> <span class=s1>&#39;healthy&#39;</span><span class=p>],</span> <span class=n>PCA_df</span><span class=p>[</span><span class=s1>&#39;PCA_2&#39;</span><span class=p>][</span><span class=n>data</span><span class=o>.</span><span class=n>disease</span> <span class=o>==</span> <span class=s1>&#39;healthy&#39;</span><span class=p>],</span> <span class=s1>&#39;o&#39;</span><span class=p>,</span> <span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.7</span><span class=p>,</span> <span class=n>color</span> <span class=o>=</span> <span class=s1>&#39;b&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;PCA_1&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;PCA_2&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>([</span><span class=s1>&#39;CRC&#39;</span><span class=p>,</span> <span class=s1>&#39;healthy&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=https://raw.githubusercontent.com/HuaZou/Image_Host/main/img/image-20221101174319124.png alt loading=lazy data-zoomable></div></div></figure></p><p>Now, what we got after applying the linear PCA transformation is a lower dimensional subspace (from 3D to 2D in this case), where the samples are “most spread” along the new feature axes.</p><ul><li>The amount of variance that each PC explains</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>#var= pca.explained_variance_ratio_</span>
</span></span><span class=line><span class=cl><span class=c1>#Cumulative Variance explains</span>
</span></span><span class=line><span class=cl><span class=n>var1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>round</span><span class=p>(</span><span class=n>pca</span><span class=o>.</span><span class=n>explained_variance_ratio_</span><span class=p>,</span> <span class=n>decimals</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span><span class=o>*</span><span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>var1</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>[12.48 20.21 23.84 26.89 29.29 31.2  33.05 34.78 36.42 37.89]
</code></pre><h2 id=deciding-how-many-principal-components-to-retain>Deciding How Many Principal Components to Retain</h2><p>In order to decide how many principal components should be retained, it is common to summarise the results of a principal components analysis by making a scree plot. More about scree plot can be found <a href=http://python-for-multivariate-analysis.readthedocs.io/a_little_book_of_python_for_multivariate_analysis.html target=_blank rel=noopener>here</a>, and <a href=https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/ target=_blank rel=noopener>here</a></p><ul><li>The amount of variance that each PC explains</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>var</span> <span class=o>=</span> <span class=n>pca</span><span class=o>.</span><span class=n>explained_variance_ratio_</span>
</span></span><span class=line><span class=cl><span class=c1>#Cumulative Variance explains</span>
</span></span><span class=line><span class=cl><span class=c1>#var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)</span>
</span></span><span class=line><span class=cl><span class=c1>#print(var1)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>var</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Scree Plot&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Principal Component&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Eigenvalue&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>leg</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>([</span><span class=s1>&#39;Eigenvalues from PCA&#39;</span><span class=p>],</span> <span class=n>loc</span><span class=o>=</span><span class=s1>&#39;best&#39;</span><span class=p>,</span> <span class=n>borderpad</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>shadow</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>markerscale</span><span class=o>=</span><span class=mf>0.4</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>leg</span><span class=o>.</span><span class=n>get_frame</span><span class=p>()</span><span class=o>.</span><span class=n>set_alpha</span><span class=p>(</span><span class=mf>0.4</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>leg</span><span class=o>.</span><span class=n>set_draggable</span><span class=p>(</span><span class=n>state</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=https://raw.githubusercontent.com/HuaZou/Image_Host/main/img/image-20221101174344139.png alt loading=lazy data-zoomable></div></div></figure></p><h2 id=static3dplot>Static3Dplot</h2><p>The most obvious change in slope in the scree plot occurs at component 3, which is the “elbow” of the scree plot. Therefore, it could be argued based on the basis of the scree plot that the first three components should be retained.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>Static3Dplot</span><span class=p>(</span><span class=n>reduced_data</span><span class=p>,</span> <span class=n>labels</span><span class=p>,</span> <span class=n>variable</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=s1>&#39;&#39;&#39;
</span></span></span><span class=line><span class=cl><span class=s1>    draw a static compositional biplot in 3d for three principal components
</span></span></span><span class=line><span class=cl><span class=s1>    Args:
</span></span></span><span class=line><span class=cl><span class=s1>        reduced_data: data processed by PCA
</span></span></span><span class=line><span class=cl><span class=s1>        labels:       labels of the original dataset
</span></span></span><span class=line><span class=cl><span class=s1>        variable:     the names of the variables of the data set     
</span></span></span><span class=line><span class=cl><span class=s1>    &#39;&#39;&#39;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>fig</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>14</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>axes</span><span class=p>(</span><span class=n>projection</span><span class=o>=</span><span class=s1>&#39;3d&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>legend</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>classes</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>n</span> <span class=o>=</span> <span class=n>reduced_data</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>colors</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=s1>&#39;b&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>reduced_data</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>reduced_data</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>z</span> <span class=o>=</span> <span class=n>reduced_data</span><span class=p>[:,</span> <span class=mi>2</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>scalex</span> <span class=o>=</span> <span class=mf>1.0</span><span class=o>/</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>-</span> <span class=n>x</span><span class=o>.</span><span class=n>min</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=n>scaley</span> <span class=o>=</span> <span class=mf>1.0</span><span class=o>/</span><span class=p>(</span><span class=n>y</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>-</span> <span class=n>y</span><span class=o>.</span><span class=n>min</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=n>scalez</span> <span class=o>=</span> <span class=mf>1.0</span><span class=o>/</span><span class=p>(</span><span class=n>z</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>-</span> <span class=n>z</span><span class=o>.</span><span class=n>min</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Scatter plot with a two-dimensional plot using normal PCA</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>classes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>scatter3D</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=n>labels</span><span class=o>==</span><span class=n>label</span><span class=p>]</span> <span class=o>*</span> <span class=n>scalex</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                     <span class=n>y</span><span class=p>[</span><span class=n>labels</span><span class=o>==</span><span class=n>label</span><span class=p>]</span> <span class=o>*</span> <span class=n>scaley</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                     <span class=n>z</span><span class=p>[</span><span class=n>labels</span><span class=o>==</span><span class=n>label</span><span class=p>]</span> <span class=o>*</span> <span class=n>scalez</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                     <span class=n>linewidth</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                     <span class=n>c</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>legend</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=s2>&#34;Group: </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>label</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>legend</span><span class=p>(</span><span class=n>legend</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># the initial angle to draw the 3d plot</span>
</span></span><span class=line><span class=cl>    <span class=n>azim</span> <span class=o>=</span> <span class=o>-</span><span class=mi>60</span>
</span></span><span class=line><span class=cl>    <span class=n>elev</span> <span class=o>=</span> <span class=mi>30</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>view_init</span><span class=p>(</span><span class=n>elev</span><span class=p>,</span> <span class=n>azim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># plot arrows as the variable contribution, each variable has a score for PCA1 and PCA2 respectively</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>quiver</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>reduced_data</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>i</span><span class=p>],</span> <span class=n>reduced_data</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=n>i</span><span class=p>],</span> <span class=n>reduced_data</span><span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=n>i</span><span class=p>],</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;k&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>arrow_length_ratio</span><span class=o>=</span><span class=mf>0.05</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>text</span><span class=p>(</span><span class=n>reduced_data</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>i</span><span class=p>]</span><span class=o>*</span><span class=mf>1.1</span><span class=p>,</span> <span class=n>reduced_data</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=n>i</span><span class=p>]</span><span class=o>*</span><span class=mf>1.1</span><span class=p>,</span> <span class=n>reduced_data</span><span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=n>i</span><span class=p>]</span><span class=o>*</span><span class=mf>1.1</span><span class=p>,</span> <span class=n>variable</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>ha</span><span class=o>=</span><span class=s1>&#39;center&#39;</span><span class=p>,</span> <span class=n>va</span><span class=o>=</span><span class=s1>&#39;center&#39;</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;k&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;PCA1&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;PCA2&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>set_zlabel</span><span class=p>(</span><span class=s1>&#39;PCA3&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Compositional Plot in 3 Dimension&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Static3Dplot</span><span class=p>(</span><span class=n>X_pca</span><span class=p>,</span> <span class=n>data</span><span class=o>.</span><span class=n>disease</span><span class=p>,</span> <span class=n>data</span><span class=o>.</span><span class=n>columns</span><span class=p>[</span><span class=mi>1</span><span class=p>:</span><span class=n>data</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]])</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=https://raw.githubusercontent.com/HuaZou/Image_Host/main/img/image-20221101174407211.png alt loading=lazy data-zoomable></div></div></figure></p><h2 id=compositional-biplot>Compositional biplot</h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.decomposition</span> <span class=kn>import</span> <span class=n>PCA</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>biplotPCA</span><span class=p>(</span><span class=n>reduced_data</span><span class=p>,</span> <span class=n>labels</span><span class=p>,</span> <span class=n>variable</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=s1>&#39;&#39;&#39;
</span></span></span><span class=line><span class=cl><span class=s1>    plot compositional biplot for two principal components
</span></span></span><span class=line><span class=cl><span class=s1>    Args:
</span></span></span><span class=line><span class=cl><span class=s1>        reduced_data: data processed by PCA
</span></span></span><span class=line><span class=cl><span class=s1>        labels:       labels of the original dataset
</span></span></span><span class=line><span class=cl><span class=s1>        variable:     the names of the variables of the data set     
</span></span></span><span class=line><span class=cl><span class=s1>    &#39;&#39;&#39;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>legend</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>classes</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>n</span> <span class=o>=</span> <span class=n>reduced_data</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>colors</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=s1>&#39;b&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>reduced_data</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>y</span> <span class=o>=</span> <span class=n>reduced_data</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>scalex</span> <span class=o>=</span> <span class=mf>1.0</span><span class=o>/</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>-</span> <span class=n>x</span><span class=o>.</span><span class=n>min</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=n>scaley</span> <span class=o>=</span> <span class=mf>1.0</span><span class=o>/</span><span class=p>(</span><span class=n>y</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>-</span> <span class=n>y</span><span class=o>.</span><span class=n>min</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Scatter plot with a two-dimensional plot using normal PCA</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>classes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=n>labels</span><span class=o>==</span><span class=n>label</span><span class=p>]</span> <span class=o>*</span> <span class=n>scalex</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>y</span><span class=p>[</span><span class=n>labels</span><span class=o>==</span><span class=n>label</span><span class=p>]</span> <span class=o>*</span> <span class=n>scaley</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>linewidth</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>c</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>legend</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=s2>&#34;Group: </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>label</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>(</span><span class=n>legend</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># plot arrows as the variable contribution, each variable has a score for PCA1 and PCA2 respectively</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>arrow</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>reduced_data</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>i</span><span class=p>],</span> <span class=n>reduced_data</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=n>i</span><span class=p>],</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;k&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>text</span><span class=p>(</span><span class=n>reduced_data</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>i</span><span class=p>]</span><span class=o>*</span><span class=mf>1.01</span><span class=p>,</span> <span class=n>reduced_data</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=n>i</span><span class=p>]</span><span class=o>*</span><span class=mf>1.01</span><span class=p>,</span> <span class=n>variable</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>ha</span><span class=o>=</span><span class=s1>&#39;center&#39;</span><span class=p>,</span> <span class=n>va</span><span class=o>=</span><span class=s1>&#39;center&#39;</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;k&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>12</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;PCA1&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;PCA2&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Compositional biplot&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>biplotPCA</span><span class=p>(</span><span class=n>X_pca</span><span class=p>,</span> <span class=n>data</span><span class=o>.</span><span class=n>disease</span><span class=p>,</span> <span class=n>data</span><span class=o>.</span><span class=n>columns</span><span class=p>[</span><span class=mi>1</span><span class=p>:</span><span class=n>data</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]])</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=https://raw.githubusercontent.com/HuaZou/Image_Host/main/img/image-20221101174434191.png alt loading=lazy data-zoomable></div></div></figure></p><blockquote><h3 id=observation>Observation</h3></blockquote><ul><li>PCA shows no significant differneces between CRC and healthy in the whole gut microbial species level</li></ul><h2 id=output>Output</h2><p>Saving the transformed and noramlized profile</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>prof</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>prof</span><span class=o>.</span><span class=n>columns</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>columns</span><span class=p>[</span><span class=mi>1</span><span class=p>:</span><span class=n>data</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=n>prof</span><span class=o>.</span><span class=n>index</span> <span class=o>=</span> <span class=n>data_df</span><span class=o>.</span><span class=n>index</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>phen</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>loc</span><span class=p>[:,</span> <span class=s1>&#39;disease&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>phen</span><span class=o>.</span><span class=n>index</span> <span class=o>=</span> <span class=n>data_df</span><span class=o>.</span><span class=n>index</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>mdat</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>merge</span><span class=p>(</span><span class=n>phen</span><span class=p>,</span> <span class=n>prof</span><span class=p>,</span> <span class=n>on</span><span class=o>=</span><span class=s2>&#34;SampleID&#34;</span><span class=p>,</span> <span class=n>how</span><span class=o>=</span><span class=s2>&#34;inner&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>mdat</span><span class=o>.</span><span class=n>to_csv</span><span class=p>(</span><span class=s1>&#39;./dataset/MergeData_clr.tsv&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>sep</span><span class=o>=</span><span class=s1>&#39;</span><span class=se>\t</span><span class=s1>&#39;</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s1>&#39;utf-8&#39;</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>mdat</span><span class=o>.</span><span class=n>head</span><span class=p>()</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img src=https://raw.githubusercontent.com/HuaZou/Image_Host/main/img/image-20221102102916069.png alt loading=lazy data-zoomable></div></div></figure></p><h2 id=a-summary-of-the-data-preprocing-approach-used-here>A Summary of the Data Preprocing Approach used here:</h2><ol><li><p>assign features to a NumPy array X, and transform the class labels from their original string representation (CRC and healthy) into integers</p></li><li><p>transform compositional data into Gaussian space</p></li><li><p>Split data into training and test sets</p></li><li><p>Standardize the data.</p></li><li><p>Obtain the Eigenvectors and Eigenvalues from the covariance matrix or correlation matrix</p></li><li><p>Sort eigenvalues in descending order and choose the kk eigenvectors that correspond to the kk largest eigenvalues where k is the number of dimensions of the new feature subspace (k≤dk≤d).</p></li><li><p>Construct the projection matrix W from the selected k eigenvectors.</p></li><li><p>Transform the original dataset X via W to obtain a k-dimensional feature subspace Y.</p></li><li><p>Visualise the PCA results via compositional plot and 3 dimensional plot.</p></li></ol><p>It is common to select a subset of features that have the largest correlation with the class labels. The effect of feature selection must be assessed within a complete modeling pipeline in order to give you an unbiased estimated of your model&rsquo;s true performance. Hence, in the next section you will first be introduced to cross-validation, before applying the PCA-based feature selection strategy in the model building pipeline.</p><h2 id=reference>Reference</h2><ul><li><a href=https://github.com/Jean-njoroge/Breast-cancer-risk-prediction target=_blank rel=noopener>Breast-cancer-risk-prediction</a></li></ul></article><style>.btn-feedback{display:inline-block}.btn-feedback-negative{margin-left:1em}.feedback--response{display:none;margin-top:1em}.feedback--response__visible{display:block}</style><div class="d-print-none widget--feedback"><h2 class=feedback--title>Feedback</h2><p class=feedback--question>Was this page helpful?</p><p class="feedback--response feedback--response-positive">🙏</p><p class="feedback--response feedback--response-negative">🙏</p><button class="btn btn-primary mb-4 btn-feedback btn-feedback-positive">
😍 Yes</button>
<button class="btn btn-primary mb-4 btn-feedback btn-feedback-negative">
😡 No</button></div><script>const btnYes=document.querySelector(".btn-feedback-positive"),btnNo=document.querySelector(".btn-feedback-negative"),responseYes=document.querySelector(".feedback--response-positive"),responseNo=document.querySelector(".feedback--response-negative"),disableButtons=()=>{btnYes.disabled=!0,btnNo.disabled=!0},sendFeedback=e=>{if(typeof gtag!="function")return;gtag("event","click",{event_category:"page_rating",event_label:window.location.pathname,value:e,transport_type:"beacon",event_callback:function(){console.debug(`✅ Feedback sent ${e}`)}})};btnYes.addEventListener("click",()=>{console.debug("Feedback response: 😍"),responseYes.classList.add("feedback--response__visible"),disableButtons(),sendFeedback(1)}),btnNo.addEventListener("click",()=>{console.debug("Feedback response: 😡"),responseNo.classList.add("feedback--response__visible"),disableButtons(),sendFeedback(0)})</script><div class=article-tags><a class="badge badge-light" href=/tag/machine-learning/>machine learning</a>
<a class="badge badge-light" href=/tag/microbiota/>microbiota</a></div><div class=article-widget><div class=post-nav><div class=post-nav-item><div class=meta-nav>Previous</div><a href=/post/machine_learning/2022-10-30-ml005-differential/ rel=next>Machine Learning on gut microbiota of patients with Colorectal cancer (5)</a></div><div class=post-nav-item><div class=meta-nav>Next</div><a href=/post/machine_learning/2022-10-28-ml003-exploratory/ rel=prev>Machine Learning on gut microbiota of patients with Colorectal cancer (3)</a></div></div></div></div><div class=body-footer><p>Last updated on Oct 29, 2022</p></div><footer class=site-footer><p class=powered-by>© 2024 Hua Zou &#183;
Rendered by <a href=https://cran.r-project.org/ target=_blank rel=noopener><i class="fab fa-r-project"></i> </a><a href=https://github.com/rstudio/blogdown target=_blank rel=noopener>blogdown</a> ,
<a href=https://sourcethemes.com/academic/ target=_blank rel=noopener>Academic theme</a> and
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a>.
<span class=float-right aria-hidden=true><a href=# id=back_to_top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer><script type=text/javascript src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></main></div></div></div><div class=page-footer></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script src=https://cdn.jsdelivr.net/gh/bryanbraun/anchorjs@4.2.2/anchor.min.js integrity="sha512-I7w3ZdSFzw5j3jU3ZkNikBNeIrl3i+hEuEdwNmqUJvwNcaBUNcijnP2gd9DtGlgVYDplfjGoD8vTNsID+lCjqg==" crossorigin=anonymous></script>
<script>anchors.add()</script><script id=page-data type=application/json>{"use_headroom":false}</script><script src=/en/js/wowchemy.min.e973d49cb2d568aa6f8eaf3638337473.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>